{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from g99 import FitsHandler as fh\n",
    "import numpy as np\n",
    "from astropy.io import fits"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-22T13:53:35.430918800Z",
     "start_time": "2024-05-22T13:53:34.199674600Z"
    }
   },
   "id": "1e360a38a3b889da"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-22T12:15:23.494055Z",
     "start_time": "2024-05-22T12:15:23.474040Z"
    }
   },
   "source": [
    "\n",
    "\n",
    "# Define where the directory is located\n",
    "datadir2 = \"/Users/stefa/OneDrive/Documenten/Blaauw images/Spectroscope/Live\"\n",
    "datadir = \"C:/Users/stefa/OneDrive/Documenten/Blaauw images/Spectroscope\"\n",
    "procdir = \"/Users/stefa/OneDrive/Documenten/Blaauw images/Spectroscope/Process/i\"\n",
    "\n",
    "# Use pathlib.Path to create a pathobject\n",
    "pathobject = Path(datadir)\n",
    "pathobject2 = Path(datadir2)\n",
    "\n",
    "myfitsfiles = []\n",
    "myfitsfiles2 = []\n",
    "\n",
    "# Loop over all files in the directory and grab the fits files\n",
    "for f in pathobject.iterdir():\n",
    "    if f.suffix.lower() in ['.fits', '.fit', '.fts']:\n",
    "        myfitsfiles.append(f)\n",
    "\n",
    "for f in pathobject2.iterdir():\n",
    "    if f.suffix.lower() in ['.fits', '.fit', '.fts']:\n",
    "        myfitsfiles2.append(f)\n"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<fits\\240422_Xs.00000001.BIAS.FIT> 18:14:30.9410\n",
      "<fits\\240422_Xs.00000002.BIAS.FIT> 18:14:39.6860\n",
      "<fits\\240422_Xs.00000003.BIAS.FIT> 18:14:48.4900\n",
      "<fits\\240422_Xs.00000004.BIAS.FIT> 18:14:57.1010\n",
      "<fits\\240422_Xs.00000005.BIAS.FIT> 18:15:05.0190\n",
      "<fits\\240422_Xs.00000006.BIAS.FIT> 18:15:12.8870\n",
      "<fits\\240422_Xs.00000007.BIAS.FIT> 18:15:21.0650\n",
      "<fits\\240422_Xs.00000008.BIAS.FIT> 18:15:29.1860\n",
      "<fits\\240422_Xs.00000009.BIAS.FIT> 18:15:37.2690\n",
      "<fits\\240422_Xs.00000010.BIAS.FIT> 18:15:45.4050\n",
      "<fits\\240422_Xs.00000011.BIAS.FIT> 18:15:53.6000\n",
      "<fits\\240422_Xs.00000012.BIAS.FIT> 18:16:01.5350\n",
      "<fits\\240422_Xs.00000013.BIAS.FIT> 18:16:09.4550\n",
      "<fits\\240422_Xs.00000014.BIAS.FIT> 18:16:17.5470\n",
      "<fits\\240422_Xs.00000015.BIAS.FIT> 18:16:25.6290\n",
      "<fits\\240422_Xs.00000016.FIT> 18:32:14.5090\n",
      "<fits\\240422_Xs.00000017.FIT> 18:32:33.5450\n",
      "<fits\\240422_Xs.00000018.FIT> 18:32:52.2830\n",
      "<fits\\240422_Xs.00000019.FIT> 18:36:16.0100\n",
      "<fits\\240422_Xs.00000020.FIT> 18:36:34.8340\n",
      "<fits\\240422_Xs.00000021.FIT> 18:36:53.7940\n",
      "<fits\\240422_Xs.00000022.FIT> 18:40:46.6830\n",
      "<fits\\240422_Xs.00000023.FIT> 18:41:25.5870\n",
      "<fits\\240422_Xs.00000024.FIT> 18:42:04.2520\n",
      "<fits\\240422_Xs.00000025.FIT> 18:43:58.9800\n",
      "<fits\\240422_Xs.00000026.FIT> 18:44:37.7090\n",
      "<fits\\240422_Xs.00000027.FIT> 18:45:16.6020\n",
      "<fits\\240422_Xs.00000028.FIT> 18:46:14.2510\n",
      "<fits\\240422_Xs.00000029.FIT> 18:46:53.1690\n",
      "<fits\\240422_Xs.00000030.FIT> 18:47:32.0420\n",
      "<fits\\240422_Xs.00000031.FIT> 18:49:52.9270\n",
      "<fits\\240422_Xs.00000032.FIT> 18:50:31.9150\n",
      "<fits\\240422_Xs.00000033.FIT> 18:51:10.8050\n",
      "<fits\\240422_Xs.00000034.FIT> 18:55:57.8000\n",
      "<fits\\240422_Xs.00000035.FIT> 18:56:36.7040\n",
      "<fits\\240422_Xs.00000036.FIT> 18:57:15.6000\n",
      "<fits\\240422_Xs.00000037.FIT> 19:05:35.0240\n",
      "<fits\\240422_Xs.00000038.FIT> 19:05:53.9210\n",
      "<fits\\240422_Xs.00000039.FIT> 19:06:12.7170\n",
      "<fits\\240422_Xs.00000040.FIT> 19:06:31.5710\n",
      "<fits\\240422_Xs.00000041.FIT> 19:06:50.4790\n",
      "<fits\\240422_Xs.00000042.FLAT.FIT> 19:11:07.4370\n",
      "<fits\\240422_Xs.00000043.FLAT.FIT> 19:12:16.2430\n",
      "<fits\\240422_Xs.00000044.FLAT.FIT> 19:13:25.1820\n",
      "<fits\\240422_Xs.00000045.FLAT.FIT> 19:14:34.0480\n",
      "<fits\\240422_Xs.00000046.FLAT.FIT> 19:15:42.9260\n",
      "<fits\\240422_Xs.00000047.FIT> 19:53:21.5040\n",
      "<fits\\240422_Xs.00000048.FIT> 20:00:00.5670\n",
      "<fits\\240422_Xs.00000049.FIT> 20:15:04.5740\n",
      "<fits\\240422_Xs.00000050.FIT> 20:17:28.0490\n",
      "<fits\\240422_Xs.00000051.FIT> 20:18:44.1180\n",
      "<fits\\240422_Xs.00000052.FIT> 20:19:05.2840\n",
      "<fits\\240422_Xs.00000053.FIT> 20:33:35.5670\n",
      "<fits\\240422_Xs.00000054.FIT> 20:44:29.9220\n",
      "<fits\\240422_Xs.00000055.FIT> 20:56:56.7180\n",
      "<fits\\240422_Xs.00000056.FIT> 21:07:08.1400\n",
      "<fits\\240422_Xs.00000057.FIT> 21:24:28.8390\n",
      "<fits\\240422_Xs.00000058.FIT> 21:40:02.0560\n",
      "<fits\\240422_Xs.00000059.FIT> 21:50:26.3300\n",
      "<fits\\240422_Xs.00000060.FIT> 22:17:12.0310\n",
      "<fits\\240422_Xs.00000061.FIT> 22:27:57.8730\n",
      "<fits\\240422_Xs.00000062.FIT> 22:38:11.7450\n",
      "<fits\\240422_Xs.00000063.FIT> 22:48:26.3490\n",
      "<fits\\240422_Xs.00000064.FIT> 23:04:32.5120\n",
      "<fits\\240422_Xs.00000065.FIT> 23:05:16.3220\n",
      "<fits\\240422_Xs.00000066.FIT> 23:05:42.7420\n",
      "<fits\\240422_Xs.00000067.FIT> 23:06:11.6110\n",
      "<fits\\240422_Xs.00000068.FIT> 23:06:34.7790\n",
      "<fits\\240422_Xs.00000069.FIT> 23:06:55.7500\n",
      "<fits\\240422_Xs.00000071.FIT> 23:10:37.2740\n",
      "<fits\\240422_Xs.00000072.FIT> 23:10:55.5790\n",
      "<fits\\240422_Xs.00000073.FIT> 23:11:05.2790\n",
      "<fits\\240422_Xs.00000074.FIT> 23:11:14.9990\n",
      "<fits\\240422_Xs.00000075.FIT> 23:11:24.7450\n",
      "<fits\\240422_Xs.00000076.FIT> 23:11:34.3990\n",
      "<fits\\240422_Xs.00000077.FIT> 23:12:38.1200\n",
      "<fits\\240422_Xs.00000078.FIT> 23:12:48.4930\n",
      "<fits\\240422_Xs.00000079.FIT> 23:12:59.3990\n",
      "<fits\\240422_Xs.00000080.FIT> 23:13:09.1340\n",
      "<fits\\240422_Xs.00000081.FIT> 23:13:18.9300\n",
      "added 79 files\n"
     ]
    }
   ],
   "source": [
    "fits_directory = r\".\\fits\"\n",
    "handler = fh(fits_directory)\n",
    "print()\n",
    "observation = handler.get_hdus()\n",
    "\n",
    "# Comment for self: Dark Frame, Bias Frame, Flat Field, Light Frame"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-22T13:56:33.890369100Z",
     "start_time": "2024-05-22T13:56:31.697945500Z"
    }
   },
   "id": "5976524f02160d06"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create the image class\n",
    "\n",
    "class image:\n",
    "    def __init__(self, filepath, fits_imagetyp='', fits_exptime=0, fits_filter='', fits_date_obs=0, fits_naxis1=0, fits_naxis2=0, pixelsize=18):\n",
    "        self.filepath = filepath\n",
    "        self.filename = filepath.name\n",
    "        self.imagetyp = fits_imagetyp\n",
    "        self.exptime = fits_exptime\n",
    "        self.filter = fits_filter\n",
    "        self.date_obs = fits_date_obs\n",
    "        self.naxis1 = fits_naxis1\n",
    "        self.naxis2 = fits_naxis2\n",
    "        self.pixelsize = pixelsize\n",
    "\n",
    "myimages = []\n",
    "myimages2 = []\n",
    "\n",
    "# Loop over all of the filepaths in myfitsfiles, open each image, give it the image class and append it to the list of images\n",
    "for filepath in myfitsfiles:\n",
    "    hdulist = fits.open(filepath)\n",
    "    hdr = hdulist[0].header\n",
    "    # Assumes same pixelsize in x and y\n",
    "    newimage = image(filepath, hdr.get('IMAGETYP'), hdr.get('EXPTIME'), hdr.get('FILTER'), hdr.get('DATE-OBS'), hdr.get('NAXIS1'), hdr.get('NAXIS2'), hdr.get('XPIXSZ'))\n",
    "    myimages.append(newimage)\n",
    "    hdulist.close()\n",
    "\n",
    "for filepath in myfitsfiles2:\n",
    "    hdulist = fits.open(filepath)\n",
    "    hdr = hdulist[0].header\n",
    "    # Assumes same pixelsize in x and y\n",
    "    newimage = image(filepath, hdr.get('IMAGETYP'), hdr.get('EXPTIME'), hdr.get('FILTER'), hdr.get('DATE-OBS'), hdr.get('NAXIS1'), hdr.get('NAXIS2'), hdr.get('XPIXSZ'))\n",
    "    myimages2.append(newimage)\n",
    "    hdulist.close()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f4ac5e3e703ac751"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T14:05:54.824360900Z",
     "start_time": "2024-05-22T14:05:53.407239Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create the masterbias\n",
    "\n",
    "from matplotlib.pyplot import figure, show, close, subplots\n",
    "from astropy.visualization import ImageNormalize, SquaredStretch\n",
    "\n",
    "\n",
    "# Then we median combine the images        \n",
    "Bias_stack = np.stack(\n",
    "    [hdu.data for hdu in observation.files['Bias Frame']]\n",
    ")\n",
    "masterbias = np.median(Bias_stack, axis=0) # Cross-reference with stefan if this is correct\n",
    "\n",
    "\n",
    "# Then we median combine the darks\n",
    "Darks_stack = np.stack(\n",
    "    [(hdu.data - masterbias)/hdu.header['EXPTIME'] for hdu in observation.files['Dark Frame']]\n",
    ")\n",
    "masterdark = np.median(Darks_stack, axis=0)"
   ],
   "id": "81812af8ba0d6eb7",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T12:15:26.022487Z",
     "start_time": "2024-05-22T12:15:25.960425Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Let's do the masterflat next\n",
    "\n",
    "\n",
    "Flats_list = []\n",
    "count = 0\n",
    "for im in myimages2:\n",
    "    if 'flat field' in im.imagetyp.lower():\n",
    "        hdulist = fits.open(im.filepath)\n",
    "        dat = hdulist[0].data\n",
    "        Flats_list.append(dat)\n",
    "        hdulist.close\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### REDO FROM THIS POINT\n",
    "\n",
    "# After inspecting the flats we get\n",
    "Flats_list_sorted = Flats_list[0:4]"
   ],
   "id": "a6ecca69c22fbc3f",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T12:15:26.463433Z",
     "start_time": "2024-05-22T12:15:26.022487Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Then we calibrate the flats with masterbias and median combine the images (We don't need to concern with the darks as the dark current can't really build up during flats\n",
    "Flats_stack = np.stack(Flats_list_sorted-masterbias)\n",
    "Flats_median = np.median(Flats_stack)\n",
    "Flats_stack_normalized = Flats_stack/Flats_median\n",
    "masterflat_to_be_normalized = np.median(Flats_stack_normalized, axis=0)\n",
    "masterflat = masterflat_to_be_normalized/np.median(masterflat_to_be_normalized)"
   ],
   "id": "143c6add4c267cb",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T12:15:28.397860Z",
     "start_time": "2024-05-22T12:15:26.463433Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Now that we have our master calibration files we can work on our lights, first we calibrate\n",
    "lights = []\n",
    "for im in myimages2:\n",
    "    if 'light frame' in im.imagetyp.lower():\n",
    "        hdulist = fits.open(im.filepath)\n",
    "        data = hdulist[0].data.astype(float)\n",
    "        data -= masterdark*im.exptime + masterbias\n",
    "        # data /= masterflat   # Don't devide by the masterflat, because it gives weird results due to the dark patches between the emission lines\n",
    "        lights.append(data)\n",
    "        hdulist.close\n",
    "\n",
    "# Let's inspect the lights\n",
    "# c = 0\n",
    "# for obj in lights:\n",
    "#     fig = figure()\n",
    "#     frame = fig.add_subplot(1,1,1)\n",
    "#     frame.imshow(obj, interpolation='none', origin='lower', cmap='gray')\n",
    "#     frame.set_title(f\"light {c} with min: {obj.min()}, max: {obj.max()}\")\n",
    "#     show(fig)\n",
    "#     close(fig)\n",
    "#     c += 1"
   ],
   "id": "deb27ac33d466de6",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T12:15:28.931727Z",
     "start_time": "2024-05-22T12:15:28.397860Z"
    }
   },
   "cell_type": "code",
   "source": [
    "lights_sorted_galaxy = lights[32:34]+lights[36:42]\n",
    "lights_sorted_vega = lights[43:48]\n",
    "lights_sorted_moon = lights[-5:-1]\n",
    "lights_calibration = lights[21:25]\n",
    "lights_sorted_arcturus = lights[29:31]\n",
    "lights_stack = np.stack(lights_calibration)\n",
    "masterlight = np.median(lights_stack, axis=0)\n",
    "\n",
    "lights_stack_moon = np.stack(lights_sorted_moon)\n",
    "masterlight_moon = np.median(lights_stack_moon, axis=0)"
   ],
   "id": "a34d066d2c998be0",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T12:15:28.944022Z",
     "start_time": "2024-05-22T12:15:28.931727Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Now that we have a program which calibrates the images we can start on figuring out where the spectral lines are. This is easiest done by using the flat frames first slice in a vertical line\n",
    "\n",
    "vert_slice = masterflat[:,1000]\n",
    "\n",
    "# Based on the plot we want to exclude values with less then 10000 counts\n",
    "fibre_locations = np.where(vert_slice>3)[0]\n",
    "\n",
    "# Now we would like to group all of the values in a single fibre into a single median value to reduce noise, although we do clearly see that the values on the outside are significantly less then the ones in the center.\n",
    "fibre_locations_dict = {}\n",
    "i = 1\n",
    "n = \"fibre_0\"\n",
    "c = 0\n",
    "\n",
    "# Exclude outer 2, because poor signal to noise ratio \n",
    "# And add weighting, cause these tops be looking hella mid\n",
    "\n",
    "for obj in fibre_locations:\n",
    "    try:\n",
    "        if obj+1 == fibre_locations[i]:\n",
    "            try:\n",
    "                fibre_locations_dict[n].append(obj)\n",
    "            except:\n",
    "                fibre_locations_dict[n] = []\n",
    "                fibre_locations_dict[n].append(obj)\n",
    "        else:\n",
    "            fibre_locations_dict[n].append(obj)\n",
    "            c+=1\n",
    "            n = f'fibre_{c}'\n",
    "        i+=1\n",
    "\n",
    "    except:\n",
    "        fibre_locations_dict[n].append(obj)"
   ],
   "id": "cc90c3d5174a6a10",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T12:15:29.044600Z",
     "start_time": "2024-05-22T12:15:28.944022Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Now that we have the locations of the fibres we make an intensity plot of the median of all the collumns that a fibre consists of.\n",
    "def find_maximum_slice(horizontal_slice_dict):\n",
    "    '''\n",
    "    :purpose: Finds the location of the slice which contains the maximum value\n",
    "    :input: Dictionary medians of horizontal slices\n",
    "    :return: The location of the slice which contains the maximum value\n",
    "    '''\n",
    "    Total_max = np.max(horizontal_slice_dict['fibre_0'])\n",
    "    for i in horizontal_slice_dict:\n",
    "        Max_of_row = np.max(horizontal_slice_dict[i])\n",
    "        if Max_of_row>Total_max:\n",
    "            Total_max = Max_of_row\n",
    "            location = i\n",
    "    return location\n",
    "\n",
    "horizontal_slice_dict = {}\n",
    "horizontal_slice_moon_dict = {}\n",
    "flat_horizontal_slice_dict = {}\n",
    "horizontal_slice_list = []\n",
    "\n",
    "# Loop over all the fibres\n",
    "for i in fibre_locations_dict:\n",
    "    # Do the slicing\n",
    "    horizontal_slice = masterlight[fibre_locations_dict[i],:]\n",
    "    horizontal_slice_moon = masterlight_moon[fibre_locations_dict[i],:]\n",
    "    flat_horizontal_slice = masterflat[fibre_locations_dict[i], :]\n",
    "    # Take the median\n",
    "    horizontal_slices_median = np.median(horizontal_slice, axis=0)\n",
    "    horizontal_slices_median_moon = np.median(horizontal_slice_moon, axis=0)\n",
    "    flat_horizontal_slice_median = np.median(flat_horizontal_slice, axis=0)\n",
    "    # Add this median line to the dictionary\n",
    "    horizontal_slice_dict[i] = horizontal_slices_median\n",
    "    horizontal_slice_moon_dict[i] = horizontal_slices_median_moon\n",
    "    flat_horizontal_slice_dict[i] = flat_horizontal_slice_median\n",
    "    # Append list\n",
    "    horizontal_slice_list.append(horizontal_slices_median)\n",
    "\n",
    "\n",
    "# We want to save the horizontal_slice_dict and use it in further stuff\n",
    "location_of_maximum = find_maximum_slice(horizontal_slice_dict)"
   ],
   "id": "5b04a3d171dacfe",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T12:15:45.678545Z",
     "start_time": "2024-05-22T12:15:45.658675Z"
    }
   },
   "cell_type": "code",
   "source": [
    "pixels_xaxis = 2004\n",
    "\n",
    "# Location of the peaks in our image\n",
    "a1 = np.array([199,1597,1863])\n",
    "# Values from literature: Hb = 486.1, Ha = 656.3, O2 = 686.9\n",
    "c1 = np.array([486.1,656.3,686.9])\n",
    "a2 = np.arange(0,pixels_xaxis, 1)\n",
    "\n",
    "def wavelenghtfit(a1,c1):\n",
    "    ''''\n",
    "    Function to calculate the wavelenght calibration polynomial\n",
    "    input: a1 and c1 are arrays where the first is the pixel values found and c1 are the wavelength values\n",
    "    output: wavelenght calibration polynomial\n",
    "    '''\n",
    "    y = np.poly1d(np.polyfit(a1,c1,1))\n",
    "    return(y)\n",
    "\n",
    "y = (wavelenghtfit(a1,c1))\n",
    "\n",
    "wavelenght_calibrated = np.polyval(y, a2)\n",
    "\n",
    "# Test wavelenght calibration\n",
    "# fig = figure()\n",
    "# frame = fig.add_subplot(1,1,1)\n",
    "# frame.plot(wavelenght_calibrated, flat_calibrated)\n",
    "# frame.set_title(f\"{location_of_maximum} wavelenght calibrated\")\n",
    "# frame.grid()\n",
    "# show(fig)\n",
    "# close(fig)"
   ],
   "id": "f17caa25ff2393ae",
   "outputs": [],
   "execution_count": 29
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
