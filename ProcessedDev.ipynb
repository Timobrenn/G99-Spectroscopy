{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-06T09:29:12.912088Z",
     "start_time": "2024-06-06T09:29:12.912088Z"
    }
   },
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "from astropy.io import fits\n",
    "\n",
    "# Define where the directory is located\n",
    "datadir2 = \"/Users/stefa/OneDrive/Documenten/Blaauw images/Spectroscope/Live\"\n",
    "datadir = \"C:/Users/stefa/OneDrive/Documenten/Blaauw images/Spectroscope\"\n",
    "procdir = \"/Users/stefa/OneDrive/Documenten/Blaauw images/Spectroscope/Process/i\"\n",
    "\n",
    "# Use pathlib.Path to create a pathobject\n",
    "pathobject = Path(datadir)\n",
    "pathobject2 = Path(datadir2)\n",
    "\n",
    "myfitsfiles = []\n",
    "myfitsfiles2 = []\n",
    "\n",
    "# Loop over all files in the directory and grab the fits files\n",
    "for f in pathobject.iterdir():\n",
    "    if f.suffix.lower() in ['.fits', '.fit', '.fts']:\n",
    "        myfitsfiles.append(f)\n",
    "\n",
    "for f in pathobject2.iterdir():\n",
    "    if f.suffix.lower() in ['.fits', '.fit', '.fts']:\n",
    "        myfitsfiles2.append(f)\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create the image class\n",
    "\n",
    "class image:\n",
    "    def __init__(self, filepath, fits_imagetyp='', fits_exptime=0, fits_filter='', fits_date_obs=0, fits_naxis1=0, fits_naxis2=0, pixelsize=18):\n",
    "        self.filepath = filepath\n",
    "        self.filename = filepath.name\n",
    "        self.imagetyp = fits_imagetyp\n",
    "        self.exptime = fits_exptime\n",
    "        self.filter = fits_filter\n",
    "        self.date_obs = fits_date_obs\n",
    "        self.naxis1 = fits_naxis1\n",
    "        self.naxis2 = fits_naxis2\n",
    "        self.pixelsize = pixelsize\n",
    "\n",
    "myimages = []\n",
    "myimages2 = []\n",
    "\n",
    "# Loop over all of the filepaths in myfitsfiles, open each image, give it the image class and append it to the list of images\n",
    "for filepath in myfitsfiles:\n",
    "    hdulist = fits.open(filepath)\n",
    "    hdr = hdulist[0].header\n",
    "    # Assumes same pixelsize in x and y\n",
    "    newimage = image(filepath, hdr.get('IMAGETYP'), hdr.get('EXPTIME'), hdr.get('FILTER'), hdr.get('DATE-OBS'), hdr.get('NAXIS1'), hdr.get('NAXIS2'), hdr.get('XPIXSZ'))\n",
    "    myimages.append(newimage)\n",
    "    hdulist.close()\n",
    "\n",
    "for filepath in myfitsfiles2:\n",
    "    hdulist = fits.open(filepath)\n",
    "    hdr = hdulist[0].header\n",
    "    # Assumes same pixelsize in x and y\n",
    "    newimage = image(filepath, hdr.get('IMAGETYP'), hdr.get('EXPTIME'), hdr.get('FILTER'), hdr.get('DATE-OBS'), hdr.get('NAXIS1'), hdr.get('NAXIS2'), hdr.get('XPIXSZ'))\n",
    "    myimages2.append(newimage)\n",
    "    hdulist.close()\n",
    "\n",
    "    # Comment for self: Dark Frame, Bias Frame, Flat Field, Light Frame"
   ],
   "id": "4334894e63293378",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create the masterbias\n",
    "\n",
    "from matplotlib.pyplot import figure, show, close\n",
    "from astropy.visualization import ImageNormalize, SquaredStretch\n",
    "\n",
    "# Loop over all the images in our list and check if they are Bias frames, if they are we append them to the Bias_list\n",
    "Bias_list = []\n",
    "count = 0\n",
    "for im in myimages:\n",
    "    if 'bias frame' in im.imagetyp.lower():\n",
    "        hdulist = fits.open(im.filepath)\n",
    "        dat = hdulist[0].data\n",
    "        Bias_list.append(dat)\n",
    "        hdulist.close\n",
    "\n",
    "# Then we median combine the images        \n",
    "Bias_stack = np.stack(Bias_list)\n",
    "masterbias = np.median(Bias_stack, axis=0)"
   ],
   "id": "81812af8ba0d6eb7",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create the masterdark\n",
    "\n",
    "# Loop over all the images in our list and check if they are Bias frames, if they are we append them to the Bias_list\n",
    "Darks_list = []\n",
    "count = 0\n",
    "for im in myimages:\n",
    "    if 'dark frame' in im.imagetyp.lower():\n",
    "        hdulist = fits.open(im.filepath)\n",
    "        dat = hdulist[0].data\n",
    "        Darks_list.append((dat - masterbias)/im.exptime)\n",
    "        hdulist.close\n",
    "\n",
    "# Then we median combine the darks\n",
    "Darks_stack = np.stack(Darks_list)\n",
    "masterdark = np.median(Darks_stack, axis=0)"
   ],
   "id": "42bedf4721cd4363",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Let's do the masterflat next\n",
    "\n",
    "# Loop over all the images in our list and check if they are Bias frames, if they are we append them to the Bias_list\n",
    "Flats_list = []\n",
    "count = 0\n",
    "for im in myimages2:\n",
    "    if 'flat field' in im.imagetyp.lower():\n",
    "        hdulist = fits.open(im.filepath)\n",
    "        dat = hdulist[0].data\n",
    "        Flats_list.append(dat)\n",
    "        hdulist.close\n",
    "\n",
    "# # Lets inspect the Flats\n",
    "# c = 0\n",
    "# for obj in Flats_list:\n",
    "#     fig = figure()\n",
    "#     frame = fig.add_subplot(1,1,1)\n",
    "#     norm = ImageNormalize(stretch=SquaredStretch())\n",
    "#     frame.imshow(obj, interpolation='none', origin='lower', cmap='gray', norm=norm)\n",
    "#     frame.set_title(f\"{c}, min = {np.min(obj)}, max = {np.max(obj)}\")\n",
    "#     show(fig)\n",
    "#     close(fig)\n",
    "#     c += 1\n",
    "\n",
    "# After inspecting the flats we get\n",
    "Flats_list_sorted = Flats_list[0:4]"
   ],
   "id": "a6ecca69c22fbc3f",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T09:29:12.925608Z",
     "start_time": "2024-06-06T09:29:12.925608Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Then we calibrate the flats with masterbias and median combine the images (We don't need to concern with the darks as the dark current can't really build up during flats\n",
    "Flats_stack = np.stack(Flats_list_sorted-masterbias)\n",
    "Flats_median = np.median(Flats_stack)\n",
    "Flats_stack_normalized = Flats_stack/Flats_median\n",
    "masterflat_to_be_normalized = np.median(Flats_stack_normalized, axis=0)\n",
    "masterflat = masterflat_to_be_normalized/np.median(masterflat_to_be_normalized)"
   ],
   "id": "143c6add4c267cb",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T09:29:12.951251Z",
     "start_time": "2024-06-06T09:29:12.951251Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Now that we have our master calibration files we can work on our lights, first we calibrate\n",
    "lights = []\n",
    "for im in myimages2:\n",
    "    if 'light frame' in im.imagetyp.lower():\n",
    "        hdulist = fits.open(im.filepath)\n",
    "        data = hdulist[0].data.astype(float)\n",
    "        data -= masterdark*im.exptime + masterbias\n",
    "        # data /= masterflat   # Don't devide by the masterflat, because it gives weird results due to the dark patches between the emission lines\n",
    "        lights.append(data)\n",
    "        hdulist.close\n",
    "\n",
    "# Let's inspect the lights\n",
    "# c = 0\n",
    "# for obj in lights:\n",
    "#     fig = figure()\n",
    "#     frame = fig.add_subplot(1,1,1)\n",
    "#     frame.imshow(obj, interpolation='none', origin='lower', cmap='gray')\n",
    "#     frame.set_title(f\"light {c} with min: {obj.min()}, max: {obj.max()}\")\n",
    "#     show(fig)\n",
    "#     close(fig)\n",
    "#     c += 1"
   ],
   "id": "deb27ac33d466de6",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "lights_sorted_galaxy = lights[32:34]+lights[36:42]\n",
    "lights_sorted_vega = lights[43:48]\n",
    "lights_sorted_moon = lights[-5:-1]\n",
    "lights_calibration = lights[21:25]\n",
    "lights_sorted_arcturus = lights[29:31]\n",
    "lights_stack = np.stack(lights_calibration)\n",
    "masterlight = np.median(lights_stack, axis=0)\n",
    "\n",
    "lights_stack_moon = np.stack(lights_sorted_moon)\n",
    "masterlight_moon = np.median(lights_stack_moon, axis=0)"
   ],
   "id": "a34d066d2c998be0",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Now that we have a program which calibrates the images we can start on figuring out where the spectral lines are. This is easiest done by using the flat frames first slice in a vertical line\n",
    "\n",
    "vert_slice = masterflat[:,1000]\n",
    "\n",
    "# Based on the plot we want to exclude values with less then 10000 counts\n",
    "fibre_locations = np.where(vert_slice>3)[0]\n",
    "\n",
    "# Now we would like to group all of the values in a single fibre into a single median value to reduce noise, although we do clearly see that the values on the outside are significantly less then the ones in the center.\n",
    "fibre_locations_dict = {}\n",
    "i = 1\n",
    "n = \"fibre_0\"\n",
    "c = 0\n",
    "\n",
    "# Exclude outer 2, because poor signal to noise ratio \n",
    "# And add weighting, cause these tops be looking hella mid\n",
    "\n",
    "for obj in fibre_locations:\n",
    "    try:\n",
    "        if obj+1 == fibre_locations[i]:\n",
    "            try:\n",
    "                fibre_locations_dict[n].append(obj)\n",
    "            except:\n",
    "                fibre_locations_dict[n] = []\n",
    "                fibre_locations_dict[n].append(obj)\n",
    "        else:\n",
    "            fibre_locations_dict[n].append(obj)\n",
    "            c+=1\n",
    "            n = f'fibre_{c}'\n",
    "        i+=1\n",
    "\n",
    "    except:\n",
    "        fibre_locations_dict[n].append(obj)"
   ],
   "id": "cc90c3d5174a6a10",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Now that we have the locations of the fibres we make an intensity plot of the median of all the collumns that a fibre consists of.\n",
    "def find_maximum_slice(horizontal_slice_dict):\n",
    "    '''\n",
    "    :purpose: Finds the location of the slice which contains the maximum value\n",
    "    :input: Dictionary medians of horizontal slices\n",
    "    :return: The location of the slice which contains the maximum value\n",
    "    '''\n",
    "    Total_max = np.max(horizontal_slice_dict['fibre_0'])\n",
    "    for i in horizontal_slice_dict:\n",
    "        Max_of_row = np.max(horizontal_slice_dict[i])\n",
    "        if Max_of_row>Total_max:\n",
    "            Total_max = Max_of_row\n",
    "            location = i\n",
    "    return location\n",
    "\n",
    "horizontal_slice_dict = {}\n",
    "horizontal_slice_moon_dict = {}\n",
    "flat_horizontal_slice_dict = {}\n",
    "horizontal_slice_list = []\n",
    "\n",
    "# Loop over all the fibres\n",
    "for i in fibre_locations_dict:\n",
    "    # Do the slicing\n",
    "    horizontal_slice = masterlight[fibre_locations_dict[i],:]\n",
    "    horizontal_slice_moon = masterlight_moon[fibre_locations_dict[i],:]\n",
    "    flat_horizontal_slice = masterflat[fibre_locations_dict[i], :]\n",
    "    # Take the median\n",
    "    horizontal_slices_median = np.median(horizontal_slice, axis=0)\n",
    "    horizontal_slices_median_moon = np.median(horizontal_slice_moon, axis=0)\n",
    "    flat_horizontal_slice_median = np.median(flat_horizontal_slice, axis=0)\n",
    "    # Add this median line to the dictionary\n",
    "    horizontal_slice_dict[i] = horizontal_slices_median\n",
    "    horizontal_slice_moon_dict[i] = horizontal_slices_median_moon\n",
    "    flat_horizontal_slice_dict[i] = flat_horizontal_slice_median\n",
    "    # Append list\n",
    "    horizontal_slice_list.append(horizontal_slices_median)\n",
    "\n",
    "\n",
    "# We want to save the horizontal_slice_dict and use it in further stuff\n",
    "location_of_maximum = find_maximum_slice(horizontal_slice_dict)"
   ],
   "id": "5b04a3d171dacfe",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "pixels_xaxis = 2004\n",
    "\n",
    "# Location of the peaks in our image\n",
    "a1 = np.array([199,1597,1863])\n",
    "# Values from literature: Hb = 486.1, Ha = 656.3, O2 = 686.9\n",
    "c1 = np.array([486.1,656.3,686.9])\n",
    "a2 = np.arange(0,pixels_xaxis, 1)\n",
    "\n",
    "def wavelenghtfit(a1,c1):\n",
    "    ''''\n",
    "    Function to calculate the wavelenght calibration polynomial\n",
    "    input: a1 and c1 are arrays where the first is the pixel values found and c1 are the wavelength values\n",
    "    output: wavelenght calibration polynomial\n",
    "    '''\n",
    "    y = np.poly1d(np.polyfit(a1,c1,1))\n",
    "    return(y)\n",
    "\n",
    "y = (wavelenghtfit(a1,c1))\n",
    "\n",
    "wavelenght_calibrated = np.polyval(y, a2)\n",
    "\n",
    "# Test wavelenght calibration\n",
    "# fig = figure()\n",
    "# frame = fig.add_subplot(1,1,1)\n",
    "# frame.plot(wavelenght_calibrated, flat_calibrated)\n",
    "# frame.set_title(f\"{location_of_maximum} wavelenght calibrated\")\n",
    "# frame.grid()\n",
    "# show(fig)\n",
    "# close(fig)"
   ],
   "id": "f17caa25ff2393ae",
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
